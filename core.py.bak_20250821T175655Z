# core.py â€” data fetch, 16+6 scoring, multiâ€‘TF, clean Telegram text, AI hook (optional)
from __future__ import annotations
import os, math, json, hashlib
from typing import Optional, Tuple, Dict, Any, List
from datetime import datetime, timezone, timedelta

import pandas as pd
import numpy as np
import requests
from dotenv import load_dotenv

# Optional Yahoo (works well on Termux). If missing, weâ€™ll fall back to TwelveData.
try:
    import yfinance as yf
except Exception:
    yf = None

load_dotenv()

from utils import log_error, expiry_report, utc_iso, safe_getenv

# ------------- symbol helpers -------------
def map_symbol_for_yahoo(symbol: str) -> str:
    s = symbol.upper().replace(" ", "")
    if "/" in s:
        base, quote = s.split("/", 1)
        return f"{base}{quote}=X"
    if s.endswith("=X"):
        return s
    if len(s) in (6, 7, 8) and "=X" not in s:
        return f"{s}=X"
    return s

def map_symbol_for_twelvedata(symbol: str) -> str:
    s = symbol.upper().replace(" ", "")
    if s.endswith("=X"):
        s = s.replace("=X", "")
    return s.replace("/", "")

# ------------- net profile (very light) -------------
def _http_ok(url: str, timeout=3) -> bool:
    try:
        r = requests.get(url, timeout=timeout)
        return 200 <= r.status_code < 300
    except Exception:
        return False

def detect_profile_name() -> str:
    # if Yahoo responds -> land, else ship (still try both sources anyway)
    return "land" if _http_ok("https://query2.finance.yahoo.com") else "ship"

# ------------- fetchers -------------
INTERVAL_MAP = {1:"1m",5:"5m",15:"15m",30:"30m",60:"1h",120:"2h",240:"4h",1440:"1day"}

def _fetch_yahoo(symbol: str, tf_minutes: int, rows: int = 600) -> Optional[pd.DataFrame]:
    if yf is None:
        return None
    try:
        y_sym = map_symbol_for_yahoo(symbol)
        interval = INTERVAL_MAP.get(tf_minutes, "1h")
        period = "60d" if tf_minutes <= 240 else "5y"
        df = yf.download(y_sym, interval=interval, period=period, progress=False, threads=False)
        if df is None or df.empty:
            return None
        df = df.rename(columns=str.title)[["Open","High","Low","Close","Volume"]]
        df.index = pd.to_datetime(df.index, utc=True)
        if len(df) > rows: df = df.tail(rows)
        return df.dropna()
    except Exception as e:
        log_error("Yahoo fetch failed", e)
        return None

def _fetch_twelvedata(symbol: str, tf_minutes: int, rows: int = 600) -> Optional[pd.DataFrame]:
    api_key = safe_getenv("TWELVE_DATA_API_KEY")
    if not api_key:
        return None
    try:
        td_sym = map_symbol_for_twelvedata(symbol)
        interval = INTERVAL_MAP.get(tf_minutes, "1h")
        url = "https://api.twelvedata.com/time_series"
        params = {
            "symbol": td_sym, "interval": interval, "outputsize": min(rows, 5000),
            "format": "JSON", "apikey": api_key,
        }
        r = requests.get(url, params=params, timeout=7)
        r.raise_for_status()
        data = r.json()
        if "values" not in data: return None
        vals = data["values"]
        if not vals: return None
        df = pd.DataFrame(vals)
        df.rename(columns={
            "datetime":"Datetime","open":"Open","high":"High","low":"Low","close":"Close","volume":"Volume"
        }, inplace=True)
        if "Volume" not in df.columns:
            df["Volume"] = 0
        df["Datetime"] = pd.to_datetime(df["Datetime"], utc=True)
        for c in ("Open","High","Low","Close","Volume"):
            df[c] = pd.to_numeric(df[c], errors="coerce")
        df = df.dropna(subset=["Open","High","Low","Close"]).sort_values("Datetime").set_index("Datetime")
        if len(df) > rows: df = df.tail(rows)
        return df
    except Exception as e:
        log_error("TwelveData fetch failed", e)
        return None

def get_candles(symbol: str, tf_minutes: int) -> Tuple[Optional[pd.DataFrame], str, str]:
    """
    Returns (df, source_name, tf_label)
    """
    tf_label = {1:"M1",5:"M5",15:"M15",30:"M30",60:"H1",120:"H2",240:"H4",1440:"D1"}.get(tf_minutes, "H1")
    prof = detect_profile_name()
    # Try Yahoo first (usually good), then TwelveData
    df = _fetch_yahoo(symbol, tf_minutes)
    src = "Yahoo" if df is not None else ""
    if df is None:
        df = _fetch_twelvedata(symbol, tf_minutes)
        if df is not None: src = "TwelveData"
    return df, (src or "None"), tf_label

# ------------- indicators -------------
def ema(s: pd.Series, n: int): return s.ewm(span=n, adjust=False).mean()

def rsi(series: pd.Series, n=14):
    delta = series.diff()
    up = (delta.clip(lower=0)).ewm(alpha=1/n, adjust=False).mean()
    dn = (-delta.clip(upper=0)).ewm(alpha=1/n, adjust=False).mean()
    rs = up / (dn + 1e-12)
    return 100 - (100/(1+rs))

def macd(series: pd.Series, fast=12, slow=26, sig=9):
    f = ema(series, fast); s = ema(series, slow)
    line = f - s
    signal = ema(line, sig)
    hist = line - signal
    return line, signal, hist

def true_range(df: pd.DataFrame):
    prev_close = df["Close"].shift(1)
    return pd.concat([
        (df["High"]-df["Low"]).abs(),
        (df["High"]-prev_close).abs(),
        (df["Low"]-prev_close).abs()
    ], axis=1).max(axis=1)

def atr(df: pd.DataFrame, n=14) -> float:
    tr = true_range(df).rolling(n).mean()
    v = float(tr.iloc[-1]) if len(tr) else float("nan")
    return v

# ------------- candlestick patterns -------------
def is_bullish_engulfing(df: pd.DataFrame) -> bool:
    if len(df) < 2: return False
    a, b = df.iloc[-2], df.iloc[-1]
    return (a.Close < a.Open) and (b.Close > b.Open) and (b.Close > a.Open) and (b.Open < a.Close)

def is_bearish_engulfing(df: pd.DataFrame) -> bool:
    if len(df) < 2: return False
    a, b = df.iloc[-2], df.iloc[-1]
    return (a.Close > a.Open) and (b.Close < b.Open) and (b.Close < a.Open) and (b.Open > a.Close)

def is_hammer(df: pd.DataFrame) -> bool:
    if len(df) < 1: return False
    c = df.iloc[-1]
    body = abs(c.Close - c.Open)
    rng = (c.High - c.Low) + 1e-12
    lower = min(c.Open, c.Close) - c.Low
    upper = c.High - max(c.Open, c.Close)
    return (lower >= 2*body) and (upper <= body) and (body/rng <= 0.67)

def has_momentum_body(df: pd.DataFrame) -> bool:
    c = df.iloc[-1]
    body = abs(c.Close - c.Open)
    rng = (c.High - c.Low) + 1e-12
    return (body / rng) >= 0.5

# ------------- S/R & helpers -------------
def swing_levels(df: pd.DataFrame, bars=120) -> Tuple[float,float]:
    seg = df.tail(min(bars, len(df)))
    return float(seg.High.max()), float(seg.Low.min())

def fibo_touch(px: float, hi: float, lo: float, tol=0.003) -> bool:
    if hi <= lo: return False
    diff = hi - lo
    for r in (0.382, 0.5, 0.618):
        level = lo + r*diff
        if abs(px - level) / diff <= tol:
            return True
    return False

def tf_label(minutes: int) -> str:
    return {1:"M1",5:"M5",15:"M15",30:"M30",60:"H1",120:"H2",240:"H4",1440:"D1"}.get(minutes, "H1")

# ------------- 16 + 6 scoring -------------
def score_16(df: pd.DataFrame, df_h4: Optional[pd.DataFrame]) -> Tuple[int, Dict[str,int], Dict[str,Any]]:
    """
    Return (score16, flags16, extras) where flags16 has each of the 16 boolean rules.
    """
    flags = {k:0 for k in [
        "ema_9_21","ema_20_50","rsi_zone","rsi_div","macd_hist_flip","macd_cross","adx_trend",
        "atr_detect","candle_match","mtf_confluence","fibo_area","sr_break","high_volume",
        "momentum_body","no_opposing_htf","above_200"
    ]}
    extras: Dict[str,Any] = {}

    close = df["Close"]; vol = df.get("Volume", pd.Series(index=df.index, dtype=float)).fillna(0)
    ema9, ema21 = ema(close,9), ema(close,21)
    ema20, ema50 = ema(close,20), ema(close,50)
    ema200 = ema(close,200)
    r = rsi(close)
    macd_line, macd_sig, macd_hist = macd(close)

    # 1â€“2 EMA crosses
    flags["ema_9_21"]  = int( (ema9.iloc[-2] < ema21.iloc[-2] and ema9.iloc[-1] > ema21.iloc[-1]) or
                              (ema9.iloc[-2] > ema21.iloc[-2] and ema9.iloc[-1] < ema21.iloc[-1]) )
    flags["ema_20_50"] = int( (ema20.iloc[-2] < ema50.iloc[-2] and ema20.iloc[-1] > ema50.iloc[-1]) or
                              (ema20.iloc[-2] > ema50.iloc[-2] and ema20.iloc[-1] < ema50.iloc[-1]) )

    # 3 RSI zone
    rv = float(r.iloc[-1])
    flags["rsi_zone"] = int(rv >= 60 or rv <= 40)

    # 4 RSI divergence (simple)
    def simple_divergence(series: pd.Series, osc: pd.Series, look=20):
        s = series.tail(look); o = osc.tail(look)
        ph = s.idxmax(); oh = o.idxmax()
        pl = s.idxmin(); ol = o.idxmin()
        bear = (s.iloc[-1] >= s.loc[ph]) and (o.iloc[-1] < o.loc[oh])
        bull = (s.iloc[-1] <= s.loc[pl]) and (o.iloc[-1] > o.loc[ol])
        return bear or bull
    flags["rsi_div"] = int(simple_divergence(close, r, 20))

    # 5â€“6 MACD
    flags["macd_hist_flip"] = int( (macd_hist.iloc[-1] > 0 >= macd_hist.iloc[-2]) or
                                   (macd_hist.iloc[-1] < 0 <= macd_hist.iloc[-2]) )
    flags["macd_cross"] = int( (macd_line.iloc[-2] < macd_sig.iloc[-2] and macd_line.iloc[-1] > macd_sig.iloc[-1]) or
                               (macd_line.iloc[-2] > macd_sig.iloc[-2] and macd_line.iloc[-1] < macd_sig.iloc[-1]) )

    # 7 ADX ~ use DI spread proxy from MACD slope if ADX not implemented to stay light
    # (to keep dependencies small, weâ€™ll approximate trend strength by |EMA20-EMA50| slope)
    slope = (ema20.iloc[-1]-ema20.iloc[-5]) - (ema50.iloc[-1]-ema50.iloc[-5])
    flags["adx_trend"] = int(abs(slope) > 0)

    # 8 ATR detectable regime
    a = atr(df, 14)
    extras["atr"] = a
    flags["atr_detect"] = int(a > 0 and not math.isnan(a))

    # 9 candle pattern
    pat = 0
    if is_bullish_engulfing(df) or is_bearish_engulfing(df) or is_hammer(df):
        pat = 1
    elif has_momentum_body(df):
        pat = 1
    flags["candle_match"] = pat

    # 10 multi-timeframe confluence (H1 vs H4 21EMA slope agreement)
    flags["mtf_confluence"] = 0
    if df_h4 is not None and len(df_h4) > 21:
        e21_l = ema(close, 21).diff().iloc[-1]
        e21_h = ema(df_h4["Close"], 21).diff().iloc[-1]
        flags["mtf_confluence"] = int((e21_l>0 and e21_h>0) or (e21_l<0 and e21_h<0))

    # 11 fibo area
    hi, lo = swing_levels(df, 120)
    flags["fibo_area"] = int(fibo_touch(close.iloc[-1], hi, lo))

    # 12 S/R break
    flags["sr_break"] = int(close.iloc[-1] > hi or close.iloc[-1] < lo)

    # 13 high volume
    vol_ma = vol.rolling(20).mean().fillna(0)
    flags["high_volume"] = int(vol.iloc[-1] >= vol_ma.iloc[-1])

    # 14 momentum body
    flags["momentum_body"] = int(has_momentum_body(df))

    # 15 no opposing HTF pattern (simple: donâ€™t both show opposite engulfing)
    if df_h4 is not None and len(df_h4) > 2:
        opp = (is_bullish_engulfing(df) and is_bearish_engulfing(df_h4)) or \
              (is_bearish_engulfing(df) and is_bullish_engulfing(df_h4))
        flags["no_opposing_htf"] = int(not opp)
    else:
        flags["no_opposing_htf"] = 1

    # 16 above/below 200 EMA
    flags["above_200"] = int(close.iloc[-1] >= ema200.iloc[-1])

    score16 = int(sum(flags.values()))
    return score16, flags, extras

def score_6(symbol: str, tf_minutes: int, last_bar_time: datetime) -> Tuple[int, Dict[str,int], Dict[str,Any]]:
    """
    Fundamental/sentiment placeholders (wired later to your free APIs).
    For now we implement:
      - spread_ok (based on a simple default threshold)
      - not_mid_candle (avoid first/last 15% of bar)
      Others = 0 until we add sources.
    """
    flags = {k:0 for k in ["no_red_news_1h","news_sentiment_ok","no_cb_conflict","spread_ok","tg_agreement","not_mid_candle"]}
    ctx: Dict[str,Any] = {}

    # Spread threshold by rough heuristic
    majors = ("EURUSD","GBPUSD","USDJPY","USDCHF","USDCAD","AUDUSD","NZDUSD")
    thr = 1.5 if any(p in symbol.upper() for p in majors) else 2.5
    flags["spread_ok"] = 1  # until live spread is wired; treat as OK
    ctx["spread_thresh"] = thr

    # Not mid-candle (avoid first/last 15% of bar)
    now = datetime.now(timezone.utc)
    elapsed = (now - last_bar_time).total_seconds()
    period = tf_minutes * 60.0
    frac = elapsed / period if period > 0 else 0.5
    flags["not_mid_candle"] = int(0.15 <= frac <= 0.85)

    # others will be integrated in Phaseâ€‘B
    score6 = int(sum(flags.values()))
    return score6, flags, ctx

# ------------- bias & decision -------------
def detect_bias(df: pd.DataFrame) -> str:
    c = df["Close"]; ema21 = ema(c, 21); line, sig, _ = macd(c)
    bull = (c.iloc[-1] > ema21.iloc[-1]) and (line.iloc[-1] >= sig.iloc[-1])
    bear = (c.iloc[-1] < ema21.iloc[-1]) and (line.iloc[-1] <= sig.iloc[-1])
    return "bullish" if bull else ("bearish" if bear else "mixed")

def decide_action(bias: str, score16: int, score6: int) -> str:
    # simple gating: need decent technicals + minimum fundamentals
    if score16 >= 9 and score6 >= 3:
        return "BUY" if bias == "bullish" else ("SELL" if bias == "bearish" else "WAIT")
    return "WAIT"

# ------------- formatting -------------
def format_sr(symbol: str, df: pd.DataFrame) -> str:
    hi, lo = swing_levels(df, 120)
    return f"Support: {lo:.5f}\nResistance: {hi:.5f}"

def summarize_flags16(flags: Dict[str,int]) -> str:
    on = [k for k,v in flags.items() if v]
    if not on: return "None"
    nice = {
        "ema_9_21":"EMA9/21 cross","ema_20_50":"EMA20/50 cross","rsi_zone":"RSI zone",
        "rsi_div":"RSI divergence","macd_hist_flip":"MACD hist flip","macd_cross":"MACD cross",
        "adx_trend":"Trend strength","atr_detect":"ATR ok","candle_match":"Candle pattern",
        "mtf_confluence":"HTF confluence","fibo_area":"Fib area","sr_break":"S/R break",
        "high_volume":"High volume","momentum_body":"Momentum candle","no_opposing_htf":"No opposing HTF",
        "above_200":"Above 200 EMA"
    }
    return ", ".join(nice.get(k,k) for k in on)

def build_message(symbol: str, tf_label: str, last_px: float, src: str,
                  score16: int, flags16: Dict[str,int],
                  score6: int, flags6: Dict[str,int],
                  bias: str, valid_for_min=90) -> str:
    # confidence band
    score01 = min(1.0, max(0.0, (score16/16)*0.7 + (score6/6)*0.3))
    if score01 >= 0.70: band = "HIGH"
    elif score01 >= 0.50: band = "MEDIUM"
    elif score01 >= 0.30: band = "LOW"
    else: band = "WEAK"

    action = decide_action(bias, score16, score6)
    now = datetime.now(timezone.utc).replace(microsecond=0)
    valid_until = (now + timedelta(minutes=valid_for_min)).replace(microsecond=0)

    # â€œWhyâ€ line from triggered 16 rules
    why = summarize_flags16(flags16)

    # ID & footer
    payload = {
        "sym": symbol, "tf": tf_label, "src": src, "bias": bias,
        "s16": score16, "s6": score6, "px": round(last_px, 6), "ts": utc_iso()
    }
    uid = hashlib.sha1(json.dumps(payload, sort_keys=True).encode()).hexdigest()[:10]

    lines = []
    lines.append(f"ðŸ“Š *{symbol}* ({tf_label})")
    lines.append(f"ðŸ•’ Time (UTC): `{now.isoformat()}`  â€¢  Valid until: `{valid_until.isoformat()}`")
    lines.append(f"ðŸ’° Price: `{round(last_px, 6)}`  â€¢  Source: `{src}`")
    lines.append(f"ðŸŽ¯ Action: *{action}*  â€¢  Confidence: *{band}*  â€¢  Scores: `{score16}/16 + {score6}/6`")
    lines.append(f"ðŸ§  Why: {why}")
    lines.append(expiry_report())
    lines.append(f"ðŸ”– ID:{uid}")
    return "\n".join(lines)

# ------------- public entry -------------
def analyze_once(symbol: str, tf_minutes: int, df_h4_cached: Optional[pd.DataFrame] = None) -> str:
    # fetch main TF
    df, src, tf_lbl = get_candles(symbol, tf_minutes)
    if df is None or df.empty:
        return f"ðŸ“‰ *{symbol}* ({tf_label(tf_minutes)})\nNo data. WAIT."
    # H4 for confluence (if not already provided)
    if df_h4_cached is None and tf_minutes != 240:
        df_h4_cached, _, _ = get_candles(symbol, 240)

    # scoring
    score16, flags16, extras = score_16(df, df_h4_cached)
    last_ts = df.index[-1].to_pydatetime().astimezone(timezone.utc)
    score6, flags6, ctx6 = score_6(symbol, tf_minutes, last_ts)
    bias = detect_bias(df)

    last_px = float(df["Close"].iloc[-1])
    msg = build_message(symbol, tf_lbl, last_px, src, score16, flags16, score6, flags6, bias)
    return msg
